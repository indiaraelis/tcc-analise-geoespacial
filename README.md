# tcc-analise-geoespacial

Este README est√° dispon√≠vel em [Portugu√™s](#portugues).

---

## GEOSPATIAL ANALYSIS OF CASAN CONSUMER DISSATISFACTIONS IN CAMPECHE AND RIO TAVARES NEIGHBORHOODS - FLORIAN√ìPOLIS

This repository contains the Python script developed in Google Colab for the pre-processing, analysis, and clustering of CASAN consumer dissatisfaction data, specifically for the Campeche and Rio Tavares neighborhoods in Florian√≥polis/SC (period 2021-2022). The central objective is to transform raw textual data into meaningful categories for spatial analysis within the context of a Course Completion Work (TCC).

The `Processamento de dados planilha CASAN - Colab.ipynb` notebook (or the name of your .ipynb file) details an iterative text processing workflow, from basic normalization to advanced filtering methods to identify the most relevant themes of complaints.

---

## üöÄ How to Use the Code

To run this notebook, you can follow the steps below:

1.  **Access Google Colab:** Open Google Colab in your browser (requires a Google account).
2.  **Upload the Notebook:**
    * Go to `File > Upload notebook`.
    * Select the `.ipynb` file from this repository.
3.  **Upload the Data:** In the first cell of the notebook, you will be prompted to upload the Excel file with the raw data (`Teste 2 Python.xlsx`).
4.  **Execute Cells:** Run the notebook cells sequentially. Some cells will export Excel files to the Colab environment, and the final cell will allow you to download the processed result to your computer.

---

## üìù Detailed Notebook Description

The `Processamento de dados planilha CASAN - Colab.ipynb` notebook (or the name of your file) is structured into several cells, each responsible for a specific stage of the textual analysis process. Below, we detail the functionality of each one:

### **Cell 1: File Loading and Initial Visualization**

This cell is the starting point of the script, responsible for preparing the environment and loading the raw data.

* **Imports:** Imports the necessary libraries:
    * `google.colab.files`: To allow uploading files directly into the Colab environment.
    * `pandas`: Essential for data manipulation and analysis in DataFrame format.
* **File Loading:** Uses `files.upload()` to open an interactive interface where the user can select and send the Excel file (`Teste 2 Python.xlsx`) to the Colab execution environment.
* **Excel Reading:** The loaded file is read by `pd.read_excel(file_path)` and transformed into a pandas DataFrame (`df`), which will be the main data structure for future manipulations.
* **Initial Visualization:** `print(df.head())` displays the first 5 rows of the DataFrame, providing a preview of the data structure, including columns such as 'Logradouro', 'Distrito Operacional', 'Solicita√ß√£o(data)', and, crucially, 'Motivo'.

### **Cell 2: Normalization, Counting, and Basic Grouping of Reasons**

This cell performs the first level of pre-processing and an initial attempt to categorize the reasons for dissatisfaction.

* **Step 2: Reason Normalization:** The 'Motivo' column is standardized using `.str.lower().str.strip()`. This converts all text to lowercase and removes extra whitespace, ensuring that "Reason A" and "reason a " are treated as the same item.
* **Step 3: Frequency Count:** `df['Motivo'].value_counts()` calculates the frequency of each unique normalized reason, revealing the most common themes in the database.
* **Step 4: Identification of Top 10 Reasons:** `motivos_contagem.nlargest(10).index.tolist()` extracts the 10 most frequent reasons for an initial analysis.
* **Step 5: Creation of 'Group' Column:** A new column `df['Grupo'] = None` is added to the DataFrame to store the grouping categories.
* **Step 6: Basic Grouping:** A loop iterates over the 10 most frequent reasons. If a reason in a row contains (case-insensitively) one of these top 10, the 'Grupo' column for that row is filled with the corresponding reason.
* **Step 7: Display Results:** The 10 most frequent reasons and their counts are printed, providing an initial overview of the most recurring issues (e.g., "customer complains about lack of service provided...", "customer complains about service delay...").
* **Step 8: Saving Results:** The processed DataFrame, including the new 'Grupo' column, is exported to an Excel file (`resultado_agrupado.xlsx`) for future consultation or use.

### **Cell 3: Download of Processed File**

A simple but essential cell for the workflow:

* **Download:** `files.download(output_file_path)` initiates the download of the `resultado_agrupado.xlsx` file (generated in the previous cell) directly to the user's local system.

### **Cell 4: Improving Filters - Word Count (Without Stopwords)**

This cell marks the beginning of a more granular approach, focusing on individual words to identify keywords, but without removing common Portuguese words.

* **Imports:** `pandas`, `collections.Counter` (for efficient counts), and `re` (for regular expressions, useful in word extraction) are imported.
* **Data Reading:** The original Excel file is loaded again to ensure a "clean state" for the new analysis.
* **Step 1: Normalization:** The 'Motivo' column is normalized (lowercase, no extra spaces) again.
* **Step 2: Word Extraction:** Uses regular expressions (`re.findall(r'\b\w+\b', motivo)`) to extract all words from each reason and groups them into a single list.
* **Step 3: Word Frequency Count:** `Counter(todas_as_palavras)` calculates the frequency of each extracted word.
* **Step 4: Top 10 Words:** The 10 most frequent words are identified and displayed. The initial output usually reveals many "stopwords" (e.g., 'cliente', 'de', 'do', 'que', 'protocolo'), which, despite being frequent, do not carry much thematic meaning.

### **Cell 5: Word Count with Stopwords**

Improving the analysis from the previous cell, this step introduces the removal of stopwords to focus on more relevant terms.

* **Stopword Definition:** A `stopwords` list is manually created, containing common Portuguese words that are considered noise for thematic analysis (e.g., 'de', 'do', 'da', 'que', 'a', 'e', 'o', 'com', 'para', 'n√£o', 'cliente', 'reclama', 'protocolo').
* **Step 2: Word Filtering:** Words are extracted from the 'Motivo' column, but are now filtered to exclude any term present in the `stopwords` list.
* **Steps 3 and 4:** Frequency counting and identification of the 10 most frequent words are performed again, but with the cleaned word list.
* **Display Results:** The output now shows more significant and informative words, such as 'informa', 'servico', 'solicita', 'demora', 'fatura', which are better candidates for grouping.

### **Cell 6: Grouping by Relevant Terms (Variant 1)**

Based on the identified relevant terms, this cell performs a more specific grouping of reasons.

* **Selection of Terms for Grouping:** A `termos_agrupamento` list is manually defined (e.g., `['fatura', 'informa', 'servi√ßo', 'demora']`), using insights from previous cells about the most significant words.
* **Grouping:** A loop iterates over the reasons. If a reason contains any of the `termos_agrupamento`, it is categorized into that group.
* **Count by Group:** The script displays the count of manifestations for each created group, such as 'demora', 'informa', 'servi√ßo', and 'fatura'.

### **Cell 7: Grouping by Relevant Terms (Variant 2 - Excluding Relevant Ones)**

This cell further refines keyword identification, looking for new important terms by excluding those already considered "relevant" from the list of the 10 most frequent.

* **Definition of Relevant and Excluded Words:** An initial set of `palavras_relevantes` (relevant words) is defined (e.g., `['fatura', 'informa', 'deslocamento', 'demora', 'cavalete']`). These are the words that *definitely* form a group. An `palavras_excluidas` (excluded words) list is created from them.
* **Advanced Filtering:** Words are extracted from reasons, but the list of the 10 most frequent words is generated *excluding* those already relevant, allowing other important terms to "rise" in the frequency list.
* **Grouping:** Reasons are grouped based on the predefined `palavras_relevantes`. The goal is to see how these groups are distributed.

### **Cell 8: Grouping by Filtered Terms (In-depth)**

This cell expands the list of words to be excluded (stopwords) more aggressively to identify truly distinctive terms for grouping.

* **Expansion of the Exclusion List (`palavras_excluir`):** A much more comprehensive `palavras_excluir` list is created, including generic or redundant terms (e.g., 'atender', 'dizer', 'respondido', 'contato', 'receber', 'pode', 'recebido', 'esperar', 'em rela√ß√£o', 'avisar', etc.). The process is iterative, adding terms as they are identified as non-informative.
* **Refined Extraction and Filtering:** Words are extracted from reasons but filtered by this expanded exclusion list, as well as numbers and short words (< 3 characters).
* **Counting and Top 10:** The most frequent words after this rigorous filter are displayed. Terms like 'agilidade', 'execu√ß√£o', 'leitura', 'prazo', 'faturas' begin to stand out, indicating a more effective filter.
* **Dynamic Grouping:** For each word that is *not* in the exclusion list and is found in a reason, it is assigned as 'Grupo'. This aims to test a more "organic" grouping based on the most relevant remaining terms.

### **Cell 9 (and subsequent): Further Iterations and Refinements in the Exclusion List**

The subsequent cells from page 6 of the PDF (`Processamento de dados planilha CASAN - Colab.pdf`) are repetitions of the logic in Cell 8, with minor modifications to the `palavras_excluir` list.

* **Continued Expansion of `palavras_excluir`:** In each iteration, more generic or less informative words, observed in previous *outputs*, are added to the `palavras_excluir` list (e.g., 'informa', 'servi√ßo', 'solicita', 'foi', 'referente', 'est√°' in one step; 'agilidade', 'execu√ß√£o', 'sua' in another).
* **Identical Processing:** The steps of normalization, word extraction and filtering, frequency counting, display of the most frequent, grouping, and counting of groups are repeated with the updated `palavras_excluir` list.
* **Objective:** This iterative process aims to continuously refine the keyword list used to group reasons, seeking to isolate the most discriminating and significant terms for CASAN's analysis. The outputs (`Palavras mais relevantes mencionadas em MOTIVO (excluindo palavras irrelevantes):` and `Contagem de manifesta√ß√µes por grupo:`) change with each iteration, reflecting this filter improvement. Terms such as 'demora', 'fatura', 'deslocamento', 'cavalete', 'leitura', 'prazo', 'faturas', 'reclama√ß√£o', 'atraso', 'ainda' emerge as relevant after more rigorous filters.

### **Final Cell: Optimized Grouping with Predefined Groups and Export**

This section concludes the grouping process, using a predefined and optimized list of keywords to categorize reasons for dissatisfaction and export the results.

* **Definition of Words for Optimized Grouping:** `palavras_grupos = ['demora', 'fatura', 'deslocamento', 'cavalete', 'agilidade', 'execu√ß√£o', 'leitura', 'prazo', 'faturas', 'vazam', 'atraso']` defines the keywords that will be used to categorize the reasons. These are the words that, after refinement iterations, were considered most important and relevant for creating the final groups.
* **Creation of 'Group' Column:** The `df['Grupo']` column is initialized with null values.
* **Final Grouping of Reasons:** A loop iterates over each `palavra` defined in `palavras_grupos`. If a `palavra` is found in the text of a 'Motivo', that `palavra` is assigned to the 'Grupo' column for that row, categorizing it.
* **Displaying Group Count:** `contagem_grupos = df['Grupo'].value_counts()` calculates and prints the count of manifestations for each defined group, showing the final distribution of complaints by category.
* **Displaying Grouped Reasons:** `motivos_agrupados = df[df['Grupo'].notnull()][['Motivo', 'Grupo']]` filters and displays a subset of the DataFrame, showing only the manifestations that have been grouped, along with their respective groups.
* **Exporting Results:** The final DataFrame, with categorized reasons, is saved to a new Excel file (`motivos_agrupados.xlsx`).
* **Download:** The `motivos_agrupados.xlsx` Excel file is made available for download, allowing the results to be used in other tools (e.g., GIS for georeferencing and spatial analysis).

### **Final Considerations on the Grouping Process**

The cells following the final section in the PDF (`Processamento de dados planilha CASAN - Colab.pdf`, from page 10) demonstrate attempts to implement a more complex grouping, where a reason could belong to multiple groups (using lists in the 'Grupo' column). However, these approaches resulted in `TypeError` due to data type incompatibilities. The last section present in the PDF is an example of how to initialize a DataFrame with empty lists in the 'Grupo' column, serving as a demonstration of the theoretical approach for multiple groupings. The final method adopted for the TCC focused on assigning a single main group per reason, based on the detection of the most relevant keywords.

---

## üîí License

This open-source project is licensed under the **MIT License**. This means you are free to copy, modify, distribute, and use this code in private or commercial projects, provided that the copyright notice and license text are maintained.

For more details, please refer to the [LICENSE](https://www.google.com/search?q=LICENSE) file in this repository.

---

## üìä Data Used

The consumer dissatisfaction data used in this project was provided by Companhia Catarinense de √Åguas e Saneamento (CASAN) specifically for academic research purposes, as part of the author's Course Completion Work (TCC). CASAN authorized the use and eventual public disclosure of this data in the context of this work.

It is important to note that the **MIT License** applied to this repository **covers only the source code** developed for geospatial analysis. The use of raw CASAN data must comply with the terms of the original authorization granted by them for this academic project.

---

<a name="portugues"></a>


# tcc-analise-geoespacial

Este README est√° dispon√≠vel em [Ingl√™s](#tcc-analise-geoespacial).

---

## AN√ÅLISE GEOESPACIAL DAS INSATISFA√á√ïES DOS CONSUMIDORES DA CASAN NOS BAIRROS CAMPECHE E RIO TAVARES - FLORIAN√ìPOLIS

Este reposit√≥rio cont√©m o script Python desenvolvido no Google Colab para o pr√©-processamento, an√°lise e agrupamento de dados de manifesta√ß√µes de insatisfa√ß√£o da CASAN, especificamente para os bairros Campeche e Rio Tavares, em Florian√≥polis/SC (per√≠odo de 2021-2022). O objetivo central √© transformar dados textuais brutos em categorias significativas para an√°lise espacial no contexto de um Trabalho de Conclus√£o de Curso (TCC).

O notebook `Processamento de dados planilha CASAN - Colab.ipynb` (ou o nome do seu arquivo .ipynb) detalha um processo iterativo de tratamento de texto, desde a normaliza√ß√£o b√°sica at√© m√©todos de filtragem avan√ßada para identificar os temas mais relevantes das reclama√ß√µes.

---

## üöÄ Como Utilizar o C√≥digo

Para rodar este notebook, voc√™ pode seguir os passos abaixo:

1.  **Acesse o Google Colab:** Abra o Google Colab em seu navegador (requer uma conta Google).
2.  **Carregue o Notebook:**
    * V√° em `Arquivo > Fazer upload do notebook`.
    * Selecione o arquivo `.ipynb` deste reposit√≥rio.
3.  **Fa√ßa o Upload dos Dados:** Na primeira c√©lula do notebook, voc√™ ser√° solicitado a fazer o upload do arquivo Excel com os dados brutos (`Teste 2 Python.xlsx`).
4.  **Execute as C√©lulas:** Execute as c√©lulas do notebook sequencialmente. Algumas c√©lulas exportar√£o arquivos Excel para o ambiente do Colab, e a c√©lula final permitir√° o download do resultado processado para o seu computador.

---

## üìù Descri√ß√£o Detalhada do Notebook

O notebook `Processamento de dados planilha CASAN - Colab.ipynb` (ou o nome do seu arquivo) √© estruturado em v√°rias c√©lulas, cada uma respons√°vel por uma etapa espec√≠fica do processo de an√°lise textual. Abaixo, detalhamos a funcionalidade de cada uma:

### **C√©lula 1: Carregamento do Arquivo e Visualiza√ß√£o Inicial**

Esta c√©lula √© o ponto de partida do script, respons√°vel por preparar o ambiente e carregar os dados brutos.

* **Importa√ß√µes:** Importa as bibliotecas necess√°rias:
    * `google.colab.files`: Para permitir o upload de arquivos diretamente no ambiente Colab.
    * `pandas`: Fundamental para manipula√ß√£o e an√°lise de dados em formato de DataFrame.
* **Carregamento do arquivo:** Utiliza `files.upload()` para abrir uma interface interativa, onde o usu√°rio pode selecionar e enviar o arquivo Excel (`Teste 2 Python.xlsx`) para o ambiente de execu√ß√£o do Colab.
* **Leitura do Excel:** O arquivo carregado √© lido por `pd.read_excel(file_path)` e transformado em um DataFrame do pandas (`df`), que ser√° a estrutura de dados principal para as manipula√ß√µes futuras.
* **Visualiza√ß√£o inicial:** `print(df.head())` exibe as primeiras 5 linhas do DataFrame, oferecendo uma pr√©via da estrutura dos dados, incluindo colunas como 'Logradouro', 'Distrito Operacional', 'Solicita√ß√£o(data)' e, crucialmente, 'Motivo'.

### **C√©lula 2: Normaliza√ß√£o, Contagem e Agrupamento B√°sico de Motivos**

Esta c√©lula realiza o primeiro n√≠vel de pr√©-processamento e uma tentativa inicial de categoriza√ß√£o dos motivos de insatisfa√ß√£o.

* **Passo 2: Normaliza√ß√£o dos Motivos:** A coluna 'Motivo' √© padronizada utilizando `.str.lower().str.strip()`. Isso converte todo o texto para min√∫sculas e remove espa√ßos em branco extras, garantindo que "Motivo A" e "motivo a " sejam tratados como o mesmo item.
* **Passo 3: Contagem de Frequ√™ncia:** `df['Motivo'].value_counts()` calcula a frequ√™ncia de cada motivo √∫nico normalizado, revelando os temas mais comuns na base de dados.
* **Passo 4: Identifica√ß√£o dos Top 10 Motivos:** `motivos_contagem.nlargest(10).index.tolist()` extrai os 10 motivos mais frequentes para uma an√°lise inicial.
* **Passo 5: Cria√ß√£o da Coluna 'Grupo':** Uma nova coluna `df['Grupo'] = None` √© adicionada ao DataFrame para armazenar as categorias de agrupamento.
* **Passo 6: Agrupamento B√°sico:** Um loop itera sobre os 10 motivos mais frequentes. Se um motivo de uma linha contiver (de forma insens√≠vel a mai√∫sculas/min√∫sculas) um desses top 10, a coluna 'Grupo' dessa linha √© preenchida com o motivo correspondente.
* **Passo 7: Exibi√ß√£o de Resultados:** Os 10 motivos mais frequentes e suas contagens s√£o impressos, fornecendo um panorama inicial das quest√µes mais recorrentes (ex: "cliente reclama da falta de servi√ßo prestado...", "cliente reclama na demora do servi√ßo...").
* **Passo 8: Salvamento do Resultado:** O DataFrame processado, incluindo a nova coluna 'Grupo', √© exportado para um arquivo Excel (`resultado_agrupado.xlsx`) para consulta ou uso posterior.

### **C√©lula 3: Download do Arquivo Processado**

Uma c√©lula simples, mas essencial para a workflow:

* **Download:** `files.download(output_file_path)` inicia o download do arquivo `resultado_agrupado.xlsx` (gerado na c√©lula anterior) diretamente para o sistema local do usu√°rio.

### **C√©lula 4: Melhorando os Filtros - Contagem de Palavras (Sem Stopwords)**

Esta c√©lula marca o in√≠cio de uma abordagem mais granular, focando em palavras individuais para identificar termos-chave, mas sem remover palavras comuns da l√≠ngua portuguesa.

* **Importa√ß√µes:** `pandas`, `collections.Counter` (para contagens eficientes) e `re` (para express√µes regulares, √∫til na extra√ß√£o de palavras) s√£o importadas.
* **Leitura de Dados:** O arquivo Excel original √© carregado novamente para garantir um "estado limpo" para a nova an√°lise.
* **Passo 1: Normaliza√ß√£o:** A coluna 'Motivo' √© normalizada (min√∫sculas, sem espa√ßos extras) novamente.
* **Passo 2: Extra√ß√£o de Palavras:** Utiliza express√µes regulares (`re.findall(r'\b\w+\b', motivo)`) para extrair todas as palavras de cada motivo e as agrupa em uma lista √∫nica.
* **Passo 3: Contagem de Frequ√™ncia de Palavras:** `Counter(todas_as_palavras)` calcula a frequ√™ncia de cada palavra extra√≠da.
* **Passo 4: Top 10 Palavras:** As 10 palavras mais frequentes s√£o identificadas e exibidas. O output inicial geralmente revela muitas "stopwords" (ex: 'cliente', 'de', 'do', 'que', 'protocolo'), que, apesar de frequentes, n√£o carregam muito significado tem√°tico.

### **C√©lula 5: Contagem de Palavras com Stopwords**

Aprimorando a an√°lise da c√©lula anterior, esta etapa introduz a remo√ß√£o de stopwords para focar em termos mais relevantes.

* **Defini√ß√£o de Stopwords:** Uma lista `stopwords` √© criada manualmente, contendo palavras comuns em portugu√™s que s√£o consideradas ru√≠do para a an√°lise tem√°tica (ex: 'de', 'do', 'da', 'que', 'a', 'e', 'o', 'com', 'para', 'n√£o', 'cliente', 'reclama', 'protocolo').
* **Passo 2: Filtragem de Palavras:** As palavras s√£o extra√≠das da coluna 'Motivo', mas agora s√£o filtradas para excluir qualquer termo presente na lista `stopwords`.
* **Passos 3 e 4:** A contagem de frequ√™ncia e a identifica√ß√£o das 10 palavras mais frequentes s√£o realizadas novamente, mas com a lista de palavras j√° limpa.
* **Exibi√ß√£o de Resultados:** O output agora mostra palavras mais significativas e informativas, como 'informa', 'servico', 'solicita', 'demora', 'fatura', que s√£o melhores candidatas para agrupamento.

### **C√©lula 6: Agrupamento por Termos Relevantes (Variante 1)**

Com base nos termos relevantes identificados, esta c√©lula realiza um agrupamento mais espec√≠fico dos motivos.

* **Sele√ß√£o de Termos para Agrupamento:** Uma lista `termos_agrupamento` √© definida manualmente (ex: `['fatura', 'informa', 'servi√ßo', 'demora']`), utilizando os insights das c√©lulas anteriores sobre as palavras mais significativas.
* **Agrupamento:** Um loop itera sobre os motivos. Se um motivo cont√©m algum dos `termos_agrupamento`, ele √© categorizado nesse grupo.
* **Contagem por Grupo:** O script exibe a contagem de manifesta√ß√µes por cada grupo criado, como 'demora', 'informa', 'servi√ßo' e 'fatura'.

### **C√©lula 7: Agrupamento por Termos Relevantes (Variante 2 - Excluindo Relevantes)**

Esta c√©lula refina ainda mais a identifica√ß√£o de palavras-chave, procurando novos termos importantes ao excluir os j√° considerados "relevantes" da lista das 10 mais frequentes.

* **Defini√ß√£o de Palavras Relevantes e Exclu√≠das:** Um conjunto inicial de `palavras_relevantes` √© definido (ex: `['fatura', 'informa', 'deslocamento', 'demora', 'cavalete']`). Essas s√£o as palavras que *definitivamente* formam um grupo. Uma lista `palavras_excluidas` √© criada a partir delas.
* **Filtragem Avan√ßada:** As palavras s√£o extra√≠das dos motivos, mas a lista das 10 palavras mais frequentes √© gerada *excluindo* as j√° relevantes, permitindo que outros termos importantes "subam" na lista de frequ√™ncia.
* **Agrupamento:** Os motivos s√£o agrupados com base nas `palavras_relevantes` predefinidas. O objetivo √© ver como esses grupos se distribuem.

### **C√©lula 8: Agrupamento por Termos Filtrados (Aprofundado)**

Esta c√©lula expande a lista de palavras a serem exclu√≠das (stopwords) de forma mais agressiva para identificar termos verdadeiramente distintivos para o agrupamento.

* **Expans√£o da Lista de Exclus√£o (`palavras_excluir`):** Uma lista `palavras_excluir` muito mais abrangente √© criada, incluindo termos gen√©ricos ou redundantes (ex: 'atender', 'dizer', 'respondido', 'contato', 'receber', 'pode', 'recebido', 'esperar', 'em rela√ß√£o', 'avisar', etc.). O processo √© iterativo, adicionando termos conforme eles s√£o identificados como n√£o-informativos.
* **Extra√ß√£o e Filtragem Refinada:** As palavras s√£o extra√≠das dos motivos, mas filtradas por esta lista expandida de exclu√≠dos, al√©m de n√∫meros e palavras curtas (< 3 caracteres).
* **Contagem e Top 10:** As palavras mais frequentes ap√≥s este filtro rigoroso s√£o exibidas. Termos como 'agilidade', 'execu√ß√£o', 'leitura', 'prazo', 'faturas' come√ßam a se destacar, indicando um filtro mais eficaz.
* **Agrupamento Din√¢mico:** Para cada palavra que *n√£o* est√° na lista de exclu√≠dos e √© encontrada em um motivo, ela √© atribu√≠da como 'Grupo'. Isso visa testar um agrupamento mais "org√¢nico" baseado nos termos mais relevantes que restaram.

### **C√©lula 9 (e seguintes): Itera√ß√µes e Refinamentos Adicionais na Lista de Exclus√£o**

As c√©lulas subsequentes a partir da p√°gina 6 do PDF (`Processamento de dados planilha CASAN - Colab.pdf`) s√£o repeti√ß√µes da l√≥gica da C√©lula 8, com pequenas modifica√ß√µes na lista de `palavras_excluir`.

* **Expans√£o Continuada da `palavras_excluir`:** Em cada itera√ß√£o, mais palavras gen√©ricas ou menos informativas, observadas nos *outputs* anteriores, s√£o adicionadas √† lista `palavras_excluir` (ex: 'informa', 'servi√ßo', 'solicita', 'foi', 'referente', 'est√°' em uma etapa; 'agilidade', 'execu√ß√£o', 'sua' em outra).
* **Processamento Id√™ntico:** Os passos de normaliza√ß√£o, extra√ß√£o e filtragem de palavras, contagem de frequ√™ncia, exibi√ß√£o dos mais frequentes, agrupamento e contagem dos grupos s√£o repetidos com a lista `palavras_excluir` atualizada.
* **Objetivo:** Este processo iterativo visa refinar continuamente a lista de palavras-chave usadas para agrupar os motivos, buscando isolar os termos mais discriminat√≥rios e significativos para a an√°lise da CASAN. As sa√≠das (`Palavras mais relevantes mencionadas em MOTIVO (excluindo palavras irrelevantes):` e `Contagem de manifesta√ß√µes por grupo:`) mudam a cada itera√ß√£o, refletindo essa melhoria no filtro. Termos como 'demora', 'fatura', 'deslocamento', 'cavalete', 'leitura', 'prazo', 'faturas', 'reclama√ß√£o', 'atraso', 'ainda' emergem como relevantes ap√≥s os filtros mais rigorosos.

### **C√©lula Final: Agrupamento Otimizado com Grupos Predefinidos e Exporta√ß√£o**

Esta se√ß√£o conclui o processo de agrupamento, utilizando uma lista predefinida e otimizada de palavras-chave para categorizar os motivos de insatisfa√ß√£o e exportar os resultados.

* **Defini√ß√£o de Palavras para Agrupamento Otimizado:** `palavras_grupos = ['demora', 'fatura', 'deslocamento', 'cavalete', 'agilidade', 'execu√ß√£o', 'leitura', 'prazo', 'faturas', 'vazam', 'atraso']` define as palavras-chave que ser√£o usadas para categorizar os motivos. Estas s√£o as palavras que, ap√≥s as itera√ß√µes de refinamento, foram consideradas mais importantes e relevantes para a cria√ß√£o dos grupos finais.
* **Cria√ß√£o da Coluna 'Grupo':** A coluna `df['Grupo']` √© inicializada com valores nulos.
* **Agrupamento Final dos Motivos:** Um loop itera sobre cada `palavra` definida em `palavras_grupos`. Se uma `palavra` for encontrada no texto de um 'Motivo', essa `palavra` √© atribu√≠da √† coluna 'Grupo' para aquela linha, categorizando-a.
* **Exibi√ß√£o da Contagem por Grupo:** `contagem_grupos = df['Grupo'].value_counts()` calcula e imprime a contagem de manifesta√ß√µes para cada um dos grupos definidos, mostrando a distribui√ß√£o final das reclama√ß√µes por categoria.
* **Exibi√ß√£o de Motivos Agrupados:** `motivos_agrupados = df[df['Grupo'].notnull()][['Motivo', 'Grupo']]` filtra e exibe um subconjunto do DataFrame, mostrando apenas as manifesta√ß√µes que foram agrupadas, juntamente com seus respectivos grupos.
* **Exporta√ß√£o dos Resultados:** O DataFrame final, com os motivos categorizados, √© salvo em um novo arquivo Excel (`motivos_agrupados.xlsx`).
* **Download:** O arquivo Excel `motivos_agrupados.xlsx` √© disponibilizado para download, permitindo que os resultados sejam utilizados em outras ferramentas (ex: SIG para georreferenciamento e an√°lise espacial).

### **Considera√ß√µes Finais sobre o Processo de Agrupamento**

As c√©lulas posteriores √† se√ß√£o final no PDF (`Processamento de dados planilha CASAN - Colab.pdf`, a partir da p√°gina 10) demonstram tentativas de implementar um agrupamento mais complexo, onde um motivo poderia pertencer a m√∫ltiplos grupos (utilizando listas na coluna 'Grupo'). No entanto, essas abordagens resultaram em `TypeError` devido a incompatibilidades de tipo de dados. A √∫ltima se√ß√£o presente no PDF √© um exemplo de como inicializar um DataFrame com listas vazias na coluna 'Grupo', servindo como uma demonstra√ß√£o da abordagem te√≥rica para m√∫ltiplos agrupamentos. O m√©todo final adotado para o TCC focou na atribui√ß√£o de um √∫nico grupo principal por motivo, baseado na detec√ß√£o das palavras-chave mais relevantes.

---

## üîí Licen√ßa

Este projeto de c√≥digo-fonte est√° licenciado sob a **Licen√ßa MIT**. Isso significa que voc√™ pode copiar, modificar, distribuir e usar este c√≥digo em projetos privados ou comerciais, desde que o aviso de copyright e o texto da licen√ßa sejam mantidos.

Para mais detalhes, consulte o arquivo [LICENSE](https://www.google.com/search?q=LICENSE) neste reposit√≥rio.

---

## üìä Dados Utilizados

Os dados de manifesta√ß√µes de insatisfa√ß√£o utilizados neste projeto foram fornecidos pela Companhia Catarinense de √Åguas e Saneamento (CASAN) especificamente para fins de pesquisa acad√™mica, como parte do Trabalho de Conclus√£o de Curso (TCC) da autora. A CASAN autorizou o uso e a eventual publicidade desses dados no contexto deste trabalho.

√â importante notar que a **Licen√ßa MIT** aplicada a este reposit√≥rio **cobre apenas o c√≥digo-fonte** desenvolvido para a an√°lise geoespacial. O uso dos dados brutos da CASAN deve estar em conformidade com os termos da autoriza√ß√£o original concedida por eles para este projeto acad√™mico.
